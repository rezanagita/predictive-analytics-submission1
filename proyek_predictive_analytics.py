# -*- coding: utf-8 -*-
"""Proyek-Predictive-Analytics.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/185_elvXzuDGgrbQnt8orp9HPABZMMCrf

# PROYEK REGRESI : Asuransi Kesehatan

## Import Library
"""

import pandas as pd
import numpy as np
import zipfile
import os
import sklearn

import matplotlib.pyplot as plt
import seaborn as sns
from sklearn.preprocessing import StandardScaler
from sklearn.model_selection import train_test_split
from sklearn.linear_model import LinearRegression
from sklearn.ensemble import RandomForestRegressor
from sklearn.ensemble import GradientBoostingRegressor
from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score
from sklearn.model_selection import GridSearchCV

"""## Data Loading"""

# Membuat folder dataset-insurance
os.makedirs("dataset-insurance", exist_ok=True)

# Ekstrak ZIP ke folder dataset-insurance/
with zipfile.ZipFile("/content/Health Insurance Dataset.zip", 'r') as zip_ref:
    zip_ref.extractall("dataset-insurance")

# Menampilkan isi folder hasil ekstraksi
os.listdir("dataset-insurance")

# read dataset
dataset = pd.read_csv("/content/dataset-insurance/insurance.csv")
dataset

"""## EDA

### Informasi data
"""

# Check informasi dataset
dataset.info()

# check missing value
print("Missing values: ")
dataset.isna().sum()

# Check duplikasi dataset
print("Duplikasi data: ", dataset.duplicated().sum())

# Melihat statistik deskriptif
dataset.describe()

# Melihat ringkasan numeririk dan kategorikal statistik deskriptif
dataset.describe(include='all')

"""**Visualisasi analisis fitur numerik**"""

numerical_features = ["age","bmi","children","charges"]

for col in numerical_features:
    sns.set(style="whitegrid")
    fig = plt.figure(figsize=(9, 6))
    sns.histplot(dataset[col], kde=True, bins=30, color='purple')
    plt.title(f"Distribusi {col}")
    plt.xlabel(col)
    plt.ylabel("Frequency")
    plt.show()

# Pairplot relasi antara fitur numerik
sns.pairplot(dataset, vars=numerical_features, diag_kind='kde')
plt.show()

"""**Visualisasi analisis fitur kategorikal**"""

categorical_features = ["sex","smoker","region"]

for col in categorical_features:
    plt.figure(figsize=(8, 6))
    sns.countplot(x=col, data=dataset, order=dataset[col].value_counts().index)
    plt.title(f"Distribusi {col}")
    plt.xlabel(col)
    plt.ylabel("Total")
    plt.xticks(rotation=45)
    plt.show()

"""**Analisis Multivariate**"""

# Korelasi fitur numerik
matriks_korelasi = dataset[numerical_features].corr()
sns.heatmap(matriks_korelasi, annot=True, cmap='coolwarm')
plt.title("Korelasi Fitur Numerik")
plt.show()

"""**hubungan data kategori dan charges**"""

plt.figure(figsize=(12,8))
sns.boxplot(data=dataset, x='sex', y='charges', order=['male','female'])
plt.title("sex vs charges")
plt.xlabel("sex")
plt.ylabel("charges")
plt.show()

plt.figure(figsize=(12,8))
sns.boxplot(data=dataset, x='smoker', y='charges', order=['no','yes'])
plt.title("smoker vs charges")
plt.xlabel("smoker")
plt.ylabel("charges")
plt.show()

plt.figure(figsize=(12,8))
sns.boxplot(data=dataset, x='region', y='charges', order=['southeast', 'southwest','nortwest','northeast'])
plt.title("region vs charges")
plt.xlabel("region")
plt.ylabel("charges")
plt.show()

"""**hubungan fitur numerik dan charges**"""

sns.scatterplot(x='age', y='charges', hue='smoker', data=dataset)
plt.title("Age vs Charges (by smoker)")
plt.show()

sns.scatterplot(x='bmi', y='charges', hue='smoker', data=dataset)
plt.title("BMI vs Charges (by smoker)")
plt.show()

sns.scatterplot(x='children', y='charges', hue='smoker', data=dataset)
plt.title("children vs Charges (by smoker)")
plt.show()

"""**melihat outlier pada data numerik**"""

for col in numerical_features:
    plt.figure(figsize=(8, 6))
    sns.boxplot(data=dataset, y=col)
    plt.title(f"outlier {col}")
    plt.ylabel(col)
    plt.show()

"""**korelasi data kategori**"""

plt.figure(figsize=(12,6))
sns.heatmap(pd.crosstab(dataset['sex'], dataset['smoker']), annot=True, cmap='coolwarm', fmt="d")
plt.title("sex vs smoker")
plt.show()

"""## Data Preparation"""

# menyimpan salinan dataset mentah
df_raw = dataset.copy()

"""**karena terlihat ada 1 duplikasi maka langkah pertama adalah hapus duplikasi data**"""

df_raw.drop_duplicates(inplace=True)
# check data apakah masih ada duplikasi?
print("Duplikasi data: ", df_raw.duplicated().sum())

"""**melakukan one hot encoding pada data kategorikal (sex,smoker, region)**"""

categorical_features = ["sex","smoker","region"]
df_raw = pd.get_dummies(df_raw, columns=categorical_features, drop_first=True).astype(int)
df_raw

"""**Menangani outlier**"""

for col in numerical_features:
    Q1 = df_raw[col].quantile(0.25)
    Q3 = df_raw[col].quantile(0.75)
    IQR = Q3 - Q1
    lower_bound = Q1 - 1.5 * IQR
    upper_bound = Q3 + 1.5 * IQR
    df_raw = df_raw[(df_raw[col] >= lower_bound) & (df_raw[col] <= upper_bound)]

"""**Fitur engineering**

**Membuat fitur baru**
"""

# fitur baru age x smoker
df_raw['age_smoker'] = df_raw['age'] * df_raw['smoker_yes']

# fitur baru bmi x smoker
df_raw['bmi_smoker'] = df_raw['bmi'] * df_raw['smoker_yes']

# fitur baru age x bmi
df_raw['age_bmi'] = df_raw['age'] * df_raw['bmi']

df_raw

"""**melakukan StandardScaler data numerik**"""

# Standarisasi data numerik
numerical_features = ["age","bmi","children","charges"]
scaler = StandardScaler()
df_raw[numerical_features] = scaler.fit_transform(df_raw[numerical_features])

"""**Hasil akhir data preparation**"""

print('data hasil preparation:')
df_raw.head()

"""## Modeling dan Evaluation

**Memisahkan data fitur(x) dan target(y)**
"""

X = df_raw.drop(columns=['charges'])
y = df_raw['charges']

# membagi dataset menjadi training dan testing
x_train, x_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=1)

# menghitung panjang/jumlah data
print("Jumlah data: ",len(X))
# menghitung panjang/jumlah data pada x_test
print("Jumlah data latih: ",len(x_train))
# menghitung panjang/jumlah data pada x_test
print("Jumlah data test: ",len(x_test))

"""### Linear Regression"""

LR = LinearRegression().fit(x_train, y_train)

pred_LR = LR.predict(x_test)

mae_LR = mean_absolute_error(y_test, pred_LR)
mse_LR = mean_squared_error(y_test, pred_LR)
r2_LR = r2_score(y_test, pred_LR)

print(f"MAE: {mae_LR}")
print(f"MSE: {mse_LR}")
print(f"R²: {r2_LR}")

"""**Membuat dataframe untuk menyimpan hasil evaluasi**"""

data = {
    'MAE': [mae_LR],
    'MSE': [mse_LR],
    'R2': [r2_LR]
}

# Konversi dictionary menjadi DataFrame
df_results = pd.DataFrame(data, index=['Linear Regression'])
df_results

"""### Random Forest Regressor"""

RF = RandomForestRegressor(
    random_state=42,
    n_estimators=200,
    max_depth=10,
    min_samples_split=10,
    min_samples_leaf=2,
    max_features='sqrt',
    bootstrap=True,
)
RF.fit(x_train, y_train)

# Prediksi
pred_RF = RF.predict(x_test)

# Evaluasi
mae_RF = mean_absolute_error(y_test, pred_RF)
mse_RF = mean_squared_error(y_test, pred_RF)
r2_RF = r2_score(y_test, pred_RF)

# Output hasil evaluasi
print(f"MAE: {mae_RF}")
print(f"MSE: {mse_RF}")
print(f"R²: {r2_RF}")

df_results.loc['Random Forest Regression'] = [mae_RF, mse_RF, r2_RF]
df_results

"""### Gradient Boosting Regressor"""

GBR = GradientBoostingRegressor(
    n_estimators=300,
    learning_rate=0.03,
    max_depth=4,
    min_samples_split=10,
    min_samples_leaf=3,
    subsample=0.8,
    max_features='sqrt',
    random_state=42
)
GBR.fit(x_train, y_train)

pred_GBR = GBR.predict(x_test)

mae_GBR = mean_absolute_error(y_test, pred_GBR)
mse_GBR = mean_squared_error(y_test, pred_GBR)
r2_GBR = r2_score(y_test, pred_GBR)

print(f"MAE: {mae_GBR}")
print(f"MSE: {mse_GBR}")
print(f"R²: {r2_GBR}")

df_results.loc['Gradient Boosting Regression'] = [mae_GBR, mse_GBR, r2_GBR]
df_results

"""Model Random Forest Regression dan Gradient Boosting Regression memiliki selisih yang sangat kecil,pada proyek ini saya menggunakan model Gradient Boosting Regression alasannya:

- MAE (terkecil): 0.339 → paling sedikit kesalahan prediksi rata-rata.

- MSE dan R² sangat kompetitif dengan Random Forest (hanya selisih kecil).

##### Hyperparameter tuning Grid Search
**menggunakan Gradient Boosting Regressor(GBR)**
"""

gbr = GradientBoostingRegressor(
    random_state=184,
    n_iter_no_change=10,
    validation_fraction=0.1
    )

param_grid_gbr = {
    'n_estimators': [100, 200, 300],
    'learning_rate': [0.05, 0.1, 0.2],
    'max_depth': [3, 5, 7],
    'subsample': [0.8, 1.0]
}

grid_gbr = GridSearchCV(estimator=gbr, param_grid=param_grid_gbr,
                        cv=5, scoring='r2', n_jobs=-1, verbose=1)

grid_gbr.fit(x_train, y_train)

print("Best Parameters GBR:", grid_gbr.best_params_)
print("Best R² GBR:", grid_gbr.best_score_)

"""**Uji dengan data test**"""

y_pred = grid_gbr.best_estimator_.predict(x_test)
print("R² Test:", r2_score(y_test, y_pred))
print("MAE Test:", mean_absolute_error(y_test, y_pred))
print("MSE Test:", mean_squared_error(y_test, y_pred))